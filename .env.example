# Anthropic Proxy Environment Configuration
# This file contains the environment variables needed for the FastAPI application to run properly

# === Core Configuration ===
# Base URL for the upstream Anthropic API
UPSTREAM_BASE=https://api.z.ai/api/anthropic

# API key for server authentication (required)
SERVER_API_KEY=

# === Request Forwarding ===
# Whether to forward the client's API key to the upstream service
FORWARD_CLIENT_KEY=true

# Whether to forward count tokens requests to upstream service
FORWARD_COUNT_TO_UPSTREAM=true

# === Anthropic Beta Features ===
# Force Anthropic beta headers for all requests
FORCE_ANTHROPIC_BETA=false

# Default Anthropic beta header value when beta features are enabled
DEFAULT_ANTHROPIC_BETA=prompt-caching-2024-07-31

# === Model Configuration ===
# JSON mapping for model aliases (leave empty for no mapping)
MODEL_MAP_JSON={}

# Default models for auto-selection
AUTOTEXT_MODEL=glm-4.5
AUTOVISION_MODEL=glm-4.5

# === Token Counting ===
# Enable compatibility mode for token counting shape
COUNT_SHAPE_COMPAT=true

# Minimum number of tokens required for cacheable prompts
MIN_CACHEABLE_TOKENS=1024

# Scale token counts for vision requests
SCALE_COUNT_TOKENS_FOR_VISION=true

# === Context Window Sizes ===
# Maximum token window for text-based models
TEXT_WINDOW=128000

# Maximum token window for vision-based models
VISION_WINDOW=65000

# Scaling factor for vision token counts
VISION_COUNT_SCALE=0.0

# === Cache Configuration ===
# Cache TTL values in seconds
CACHE_DEFAULT_TTL_SECONDS=300
CACHE_1H_TTL_SECONDS=3600