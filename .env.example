# Anthropic Proxy Configuration Example
# Copy this file to .env and update with your settings

# =============================================================================
# CORE CONFIGURATION
# =============================================================================

# Your z.ai API key for accessing GLM-4.6 models
# Get this from your z.ai account dashboard
SERVER_API_KEY=your_api_key_here

# Server configuration
HOST=0.0.0.0
PORT=5000

# =============================================================================
# REQUEST FORWARDING
# =============================================================================

# Upstream API endpoints
UPSTREAM_BASE=https://api.z.ai/api/anthropic
OPENAI_UPSTREAM_BASE=https://api.z.ai/api/coding/paas/v4

# Request timeout settings
REQUEST_TIMEOUT=300
CONNECT_TIMEOUT=60

# =============================================================================
# MODEL CONFIGURATION
# =============================================================================

# Default models for different content types
AUTOTEXT_MODEL=glm-4.6
AUTOVISION_MODEL=glm-4.6v

# Text endpoint preference (auto|openai|anthropic)
TEXT_ENDPOINT_PREFERENCE=auto

# Enable thinking parameter for OpenAI requests
ENABLE_ZAI_THINKING=true

# =============================================================================
# TOKEN SCALING
# =============================================================================

# Expected token limits for scaling calculations
ANTHROPIC_EXPECTED_TOKENS=200000
OPENAI_EXPECTED_TOKENS=200000

# Real model context windows
REAL_TEXT_MODEL_TOKENS=200000
REAL_VISION_MODEL_TOKENS=65536

# =============================================================================
# TOKEN VALIDATION
# =============================================================================

# Enable/disable token accuracy validation
ENABLE_TOKEN_VALIDATION=true

# Token accuracy thresholds (percentage)
TOKEN_ACCURACY_WARNING_THRESHOLD=90
TOKEN_ACCURACY_ERROR_THRESHOLD=80

# =============================================================================
# AI-POWERED MESSAGE CONDENSATION
# =============================================================================

# Enable intelligent message condensation
ENABLE_MESSAGE_CONDENSATION=true

# Condensation thresholds
CONDENSATION_WARNING_THRESHOLD=0.80
CONDENSATION_CRITICAL_THRESHOLD=0.90
CONDENSATION_EMERGENCY_THRESHOLD=0.95

# Model for condensation requests
CONDENSATION_MODEL=glm-4.6

# =============================================================================
# ENVIRONMENT DETAILS DEDUPLICATION
# =============================================================================

# Enable environment details deduplication
ENABLE_ENVIRONMENT_DEDUPLICATION=true

# Deduplication strategies
ENVIRONMENT_DEDUPLICATION_STRATEGY=exact_match
ENVIRONMENT_DEDUPLICATION_SIMILARITY_THRESHOLD=0.9

# =============================================================================
# ACCURATE TOKEN COUNTING
# =============================================================================

# Enable tiktoken-based accurate counting
ENABLE_ACCURATE_TOKEN_COUNTING=true

# Token counting model
TOKEN_COUNTING_MODEL=cl100k_base

# =============================================================================
# IMAGE AGE MANAGEMENT
# =============================================================================

# Image age management settings
IMAGE_AGE_THRESHOLD=3
CACHE_CONTEXT_MESSAGES=2

# Image age truncation message template
IMAGE_AGE_TRUNCATION_MESSAGE=[Previous images in conversation context: {descriptions}]

# =============================================================================
# CACHE CONFIGURATION
# =============================================================================

# File-based cache settings
IMAGE_DESCRIPTION_CACHE_SIZE=1000
CACHE_DIR=./cache
CACHE_ENABLE_LOGGING=true

# Cache performance settings
CACHE_ASYNC_WRITE=true
CACHE_COMPRESSION=true

# =============================================================================
# CONTEXT PERFORMANCE LOGGING
# =============================================================================

# Enable context management performance logging
ENABLE_CONTEXT_PERFORMANCE_LOGGING=true

# Performance logging thresholds
CONTEXT_LOGGING_WARNING_THRESHOLD_MS=1000
CONTEXT_LOGGING_ERROR_THRESHOLD_MS=5000

# =============================================================================
# LOG ROTATION & COMPRESSION
# =============================================================================

# Enable automatic log rotation
UPSTREAM_LOG_ROTATION=true

# Rotation settings
UPSTREAM_LOG_MAX_SIZE_MB=50
UPSTREAM_LOG_BACKUP_COUNT=10
UPSTREAM_LOG_COMPRESSION=true
UPSTREAM_LOG_COMPRESS_IMMEDIATELY=true

# Cleanup settings
UPSTREAM_LOG_RETENTION_DAYS=30
LOG_CLEANUP_INTERVAL_HOURS=24

# =============================================================================
# LOGGING CONFIGURATION
# =============================================================================

# Log level (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# Performance logging level (max_detail|balanced|performance|minimal)
LOGGING_PERFORMANCE_LEVEL=balanced

# Enable structured logging
ENABLE_STRUCTURED_LOGGING=true

# =============================================================================
# DEVELOPMENT SETTINGS
# =============================================================================

# Enable debug mode (additional logging, reduced security)
DEBUG=false

# Enable CORS for development
ENABLE_CORS=false

# CORS allowed origins (comma-separated)
CORS_ORIGINS=http://localhost:3000,http://localhost:8080

# =============================================================================
# MONITORING & HEALTH
# =============================================================================

# Enable health check endpoint
ENABLE_HEALTH_CHECK=true

# Health check endpoint path
HEALTH_CHECK_PATH=/health

# Enable metrics endpoint
ENABLE_METRICS=false

# Metrics endpoint path
METRICS_PATH=/metrics

# =============================================================================
# SECURITY SETTINGS
# =============================================================================

# Rate limiting (requests per minute)
RATE_LIMIT_PER_MINUTE=60

# Maximum request size (MB)
MAX_REQUEST_SIZE_MB=100

# Enable request ID tracking
ENABLE_REQUEST_ID_TRACKING=true

# =============================================================================
# DOCKER DEPLOYMENT
# =============================================================================

# Container configuration
CONTAINER_NAME=anthropic-proxy
CONTAINER_RESTART_POLICY=unless-stopped

# Volume mounts (comma-separated)
VOLUME_MOUNTS=./logs:/app/logs,./cache:/app/cache

# Environment variables for container
CONTAINER_ENV=NODE_ENV=production,LOG_LEVEL=INFO