# Anthropic Proxy Environment Configuration (example)
# Keep it minimal; most users don't need to set anything.

# Upstream endpoints
UPSTREAM_BASE=https://api.z.ai/api/anthropic
OPENAI_UPSTREAM_BASE=https://api.z.ai/api/coding/paas/v4

# Auth (optional) â€” Not required if clients send their own keys.
# SERVER_API_KEY=
# FORWARD_CLIENT_KEY=true

# Token counting (optional)
# FORWARD_COUNT_TO_UPSTREAM=true
# COUNT_SHAPE_COMPAT=true

# Models (optional)
# AUTOTEXT_MODEL=glm-4.5
# AUTOVISION_MODEL=glm-4.5v
# OPENAI_MODELS_LIST_JSON=["glm-4.5","glm-4.5v"]
# MODEL_MAP_JSON={}

# Token scaling (optional)
# SCALE_COUNT_TOKENS_FOR_VISION=true
# TEXT_WINDOW=200000
# VISION_WINDOW=65535

# Anthropic Beta features (optional)
# FORCE_ANTHROPIC_BETA=false
# DEFAULT_ANTHROPIC_BETA=prompt-caching-2024-07-31